{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obkBiYarba20"
      },
      "source": [
        "#1. \tIE: Triplet Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e0tR95c4fcR",
        "outputId": "4854b3a2-cdb7-4505-9e3b-f4031008bba9"
      },
      "source": [
        "!pip install spacy\r\n",
        "!python3 -m spacy download en_core_web_sm\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (53.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (53.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntJ_Td3G_SdS"
      },
      "source": [
        "import spacy\r\n",
        "from spacy.lang.en import English\r\n",
        "import networkx as nx\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxnsMJ_K4fXF"
      },
      "source": [
        "def getSentences(text):\r\n",
        "    nlp = English()\r\n",
        "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\r\n",
        "    document = nlp(text)\r\n",
        "    return [sent.string.strip() for sent in document.sents]\r\n",
        "\r\n",
        "def printToken(token):\r\n",
        "    print(token.text, \"->\", token.dep_)\r\n",
        "\r\n",
        "def appendChunk(original, chunk):\r\n",
        "    return original + ' ' + chunk\r\n",
        "\r\n",
        "def isRelationCandidate(token):\r\n",
        "    deps = [\"ROOT\", \"adj\", \"attr\", \"agent\", \"amod\"]\r\n",
        "    return any(subs in token.dep_ for subs in deps)\r\n",
        "\r\n",
        "def isConstructionCandidate(token):\r\n",
        "    deps = [\"compound\", \"prep\", \"conj\", \"mod\"]\r\n",
        "    return any(subs in token.dep_ for subs in deps)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjHN5H1p4fUe"
      },
      "source": [
        "def processSubjectObjectPairs(tokens):\r\n",
        "    subject = ''\r\n",
        "    object = ''\r\n",
        "    relation = ''\r\n",
        "    subjectConstruction = ''\r\n",
        "    objectConstruction = ''\r\n",
        "    for token in tokens:\r\n",
        "        printToken(token)\r\n",
        "        if \"punct\" in token.dep_:\r\n",
        "            continue\r\n",
        "        if isRelationCandidate(token):\r\n",
        "            relation = appendChunk(relation, token.lemma_)\r\n",
        "        if isConstructionCandidate(token):\r\n",
        "            if subjectConstruction:\r\n",
        "                subjectConstruction = appendChunk(subjectConstruction, token.text)\r\n",
        "            if objectConstruction:\r\n",
        "                objectConstruction = appendChunk(objectConstruction, token.text)\r\n",
        "        if \"subj\" in token.dep_:\r\n",
        "            subject = appendChunk(subject, token.text)\r\n",
        "            subject = appendChunk(subjectConstruction, subject)\r\n",
        "            subjectConstruction = ''\r\n",
        "        if \"obj\" in token.dep_:\r\n",
        "            object = appendChunk(object, token.text)\r\n",
        "            object = appendChunk(objectConstruction, object)\r\n",
        "            objectConstruction = ''\r\n",
        "\r\n",
        "  # printing triplets of given sentence\r\n",
        "    print (\"\\nThe triplet of the given sentence is: \\nSubject: \", subject.strip(),\r\n",
        "            \",\\nRelation: \", relation.strip(),\r\n",
        "            \",\\nObject: \", object.strip())\r\n",
        "    return (subject.strip(), relation.strip(), object.strip())\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLU5nvf54fNu"
      },
      "source": [
        "def processSentence(sentence):\r\n",
        "    tokens = nlp_model(sentence)\r\n",
        "    return processSubjectObjectPairs(tokens)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWYrJXE14fGR",
        "outputId": "43a3a7d9-2c02-4c95-a773-631e05aebde2"
      },
      "source": [
        "if __name__ == \"__main__\":\r\n",
        "\r\n",
        "    text = \"The designer confirmed that all fittings were conducted via Zoom due to the Covid-19 pandemic.\" \\\r\n",
        "            \"Miley Cyrus appeared in a football jersey-inspired top and denim shorts by Gucci. Tom Brady was spotted before kick off in a casual\" \r\n",
        "    sentences = getSentences(text)\r\n",
        "    nlp_model = spacy.load('en_core_web_sm')\r\n",
        "\r\n",
        "    \r\n",
        "    triples = []\r\n",
        "    print (text)\r\n",
        "    for sentence in sentences:\r\n",
        "        triples.append(processSentence(sentence))\r\n",
        "\r\n",
        "    print(triples)\r\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The designer confirmed that all fittings were conducted via Zoom due to the Covid-19 pandemic.Miley Cyrus appeared in a football jersey-inspired top and denim shorts by Gucci. Tom Brady was spotted before kick off in a casual\n",
            "The -> det\n",
            "designer -> nsubj\n",
            "confirmed -> ROOT\n",
            "that -> mark\n",
            "all -> det\n",
            "fittings -> nsubjpass\n",
            "were -> auxpass\n",
            "conducted -> ccomp\n",
            "via -> prep\n",
            "Zoom -> pobj\n",
            "due -> prep\n",
            "to -> pcomp\n",
            "the -> det\n",
            "Covid-19 -> compound\n",
            "pandemic -> pobj\n",
            ". -> punct\n",
            "\n",
            "The triplet of the given sentence is: \n",
            "Subject:  designer fittings ,\n",
            "Relation:  confirm ,\n",
            "Object:  Zoom pandemic\n",
            "Miley -> compound\n",
            "Cyrus -> nsubj\n",
            "appeared -> ROOT\n",
            "in -> prep\n",
            "a -> det\n",
            "football -> compound\n",
            "jersey -> pobj\n",
            "- -> punct\n",
            "inspired -> amod\n",
            "top -> amod\n",
            "and -> cc\n",
            "denim -> conj\n",
            "shorts -> appos\n",
            "by -> prep\n",
            "Gucci -> pobj\n",
            ". -> punct\n",
            "\n",
            "The triplet of the given sentence is: \n",
            "Subject:  Cyrus ,\n",
            "Relation:  appear inspire top ,\n",
            "Object:  jersey Gucci\n",
            "Tom -> compound\n",
            "Brady -> nsubjpass\n",
            "was -> auxpass\n",
            "spotted -> ROOT\n",
            "before -> prep\n",
            "kick -> pobj\n",
            "off -> prt\n",
            "in -> prep\n",
            "a -> det\n",
            "casual -> pobj\n",
            "\n",
            "The triplet of the given sentence is: \n",
            "Subject:  Brady ,\n",
            "Relation:  spot ,\n",
            "Object:  kick casual\n",
            "[('designer fittings', 'confirm', 'Zoom pandemic'), ('Cyrus', 'appear inspire top', 'jersey Gucci'), ('Brady', 'spot', 'kick casual')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Hg35w_4e-4"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fODsIouMbkug"
      },
      "source": [
        "#2. WordNet Task: (use the nltk wordnet library provided in the source code) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8EvFKlIxEaG",
        "outputId": "757d1b61-8876-4615-a66b-42214885cc2e"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrQlGCUs66Dl"
      },
      "source": [
        "##1.\tHyponym (a more specific concept)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osoJyl2qyICE",
        "outputId": "a99f1426-e80b-4692-b4f8-7c6a8505dd41"
      },
      "source": [
        "vehicle_synset = wn.synset('play.n.01')\r\n",
        "# getting sorted list of HYPONYMS from vehicle_synset\r\n",
        "vehicle_synset.hyponyms()\r\n",
        "# somethiing like child words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('grand_guignol.n.01'),\n",
              " Synset('miracle_play.n.01'),\n",
              " Synset('morality_play.n.01'),\n",
              " Synset('mystery_play.n.01'),\n",
              " Synset('passion_play.n.01'),\n",
              " Synset('playlet.n.01'),\n",
              " Synset('satyr_play.n.01'),\n",
              " Synset('theater_of_the_absurd.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlTeUlje67Z7"
      },
      "source": [
        "##2.\tHypernym (a more general concept)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKFRTl030xtl",
        "outputId": "2ef026b1-cfe3-458d-8a12-0aca37c13c4b"
      },
      "source": [
        "\r\n",
        "vehicle_synset = wn.synset('party.n.02')\r\n",
        "# getting sorted list of HYPONYMS from vehicle_synset\r\n",
        "sorted([lemma.name() for synset in vehicle_synset.hypernyms() for lemma in synset.lemmas()])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['social_affair', 'social_gathering']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvaKYEnK68SB"
      },
      "source": [
        "##3.\tMeronym (denotes a part of something)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MISobpjA1D7m",
        "outputId": "60e3c725-30e7-4b7e-f66f-fb88dc663e1b"
      },
      "source": [
        "\r\n",
        "animal_synset = wn.synset('bird.n.01')\r\n",
        "# getting sorted list of HYPONYMS from vehicle_synset\r\n",
        "print(animal_synset.substance_meronyms())\r\n",
        "print(animal_synset.part_meronyms())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[Synset('air_sac.n.03'), Synset('beak.n.02'), Synset('bird's_foot.n.01'), Synset('bird.n.02'), Synset('feather.n.01'), Synset('furcula.n.01'), Synset('hindquarters.n.02'), Synset('pennon.n.02'), Synset('syrinx.n.02'), Synset('uropygial_gland.n.01'), Synset('uropygium.n.01'), Synset('wing.n.01')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBLSxqJS688Y"
      },
      "source": [
        "##4.\tHolonym (denotes a membership to something)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYPQUGkC1DwS",
        "outputId": "fe905fe8-0dc8-4d5f-f160-b52ca4025357"
      },
      "source": [
        "\r\n",
        "human_synset = wn.synset('human.n.01')\r\n",
        "# hyponyms for human\r\n",
        "human_synset.hyponyms()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('homo_erectus.n.01'),\n",
              " Synset('homo_habilis.n.01'),\n",
              " Synset('homo_sapiens.n.01'),\n",
              " Synset('homo_soloensis.n.01'),\n",
              " Synset('neandertal_man.n.01'),\n",
              " Synset('rhodesian_man.n.01'),\n",
              " Synset('world.n.08')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQS45wmT69dL"
      },
      "source": [
        "##5.\tEntailment (denotes how verbs are involved)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn3oPxjd1DgG",
        "outputId": "c7fda736-cb1e-491a-a4a1-a55e38c979f3"
      },
      "source": [
        "stand_synset = wn.synset('sit.v.01')\r\n",
        "# entailment for verb stand\r\n",
        "stand_synset.entailments()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('sit_down.v.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGkvkHF1DEN"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}